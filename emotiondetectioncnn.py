# -*- coding: utf-8 -*-
"""EmotionDetectionCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gBfe79mPFxzRcsOmWxNWhkhHNmfvhJdw
"""

import zipfile
with zipfile.ZipFile('/content/archive (1) (1).zip', 'r') as zip_ref:
    zip_ref.extractall('/content/')

train_dir = '/content/train'
val_dir = '/content/test'

import os
import numpy as np
import cv2
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns

# Load and preprocess dataset
def load_images_for_cnn(folder):
    images = []
    labels = []
    for label in os.listdir(folder):
        label_path = os.path.join(folder, label)
        for filename in os.listdir(label_path):
            img_path = os.path.join(label_path, filename)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale
            img = cv2.resize(img, (48, 48))  # Resize to 48x48
            if img is not None:
                images.append(img)
                labels.append(label)
    return np.array(images), np.array(labels)

# Load the dataset
train_dir = '/content/train'
val_dir = '/content/test'
X_train, y_train = load_images_for_cnn(train_dir)
X_test, y_test = load_images_for_cnn(val_dir)

# Normalize the data
X_train = X_train.astype('float32') / 255.0  # Normalize to [0, 1]
X_test = X_test.astype('float32') / 255.0  # Normalize to [0, 1]

# Convert string labels to numerical labels
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Compute class weights to address class imbalance
class_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)
class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Create a more complex CNN model
def create_model():
    model = Sequential()
    model.add(Input(shape=(48, 48, 1)))  # Input layer
    model.add(Conv2D(32, (3, 3), activation='relu'))
    model.add(BatchNormalization())  # Add Batch Normalization
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(BatchNormalization())  # Add Batch Normalization
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(BatchNormalization())  # Add Batch Normalization
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Flatten())
    model.add(Dense(256, activation='relu'))
    model.add(Dropout(0.5))  # Dropout for regularization
    model.add(Dense(len(np.unique(y_train_encoded)), activation='softmax'))  # Output layer
    return model

# Prepare for training
num_epochs = 50  # Increased number of epochs for better training
batch_size = 64

# Use callbacks for monitoring
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True)

# Create and compile the model
model = create_model()
model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])

# Fit the model with data augmentation and class weights
model_info = model.fit(datagen.flow(X_train.reshape(-1, 48, 48, 1), y_train_encoded, batch_size=batch_size),
                        validation_data=(X_test.reshape(-1, 48, 48, 1), y_test_encoded),
                        epochs=num_epochs,
                        class_weight=class_weights_dict,
                        callbacks=[early_stopping, model_checkpoint])

# Plot training history
def plot_model_history(model_history):
    fig, axs = plt.subplots(1, 2, figsize=(15, 5))

    # Summarize history for accuracy
    axs[0].plot(range(1, len(model_history.history['accuracy']) + 1), model_history.history['accuracy'])
    axs[0].plot(range(1, len(model_history.history['val_accuracy']) + 1), model_history.history['val_accuracy'])
    axs[0].set_title('Model Accuracy')
    axs[0].set_ylabel('Accuracy')
    axs[0].set_xlabel('Epoch')
    axs[0].legend(['train', 'val'], loc='best')

    # Summarize history for loss
    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])
    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1), model_history.history['val_loss'])
    axs[1].set_title('Model Loss')
    axs[1].set_ylabel('Loss')
    axs[1].set_xlabel('Epoch')
    axs[1].legend(['train', 'val'], loc='best')

    # Show the plot
    plt.show()

# Plot training history
plot_model_history(model_info)

# Load the best model
model.load_weights('best_model.keras')

# Predictions on the test set
y_pred = model.predict(X_test.reshape(-1, 48, 48, 1))
y_pred_classes = np.argmax(y_pred, axis=1)

# Generate confusion matrix and classification report
cm = confusion_matrix(y_test_encoded, y_pred_classes)
report = classification_report(y_test_encoded, y_pred_classes, target_names=label_encoder.classes_)

print("\nConfusion Matrix:\n", cm)
print("\nClassification Report:\n", report)

# Plot the confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# Testing with a new image
def preprocess_image(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale
    img = cv2.resize(img, (48, 48))  # Resize to 48x48
    img = img.astype('float32') / 255.0  # Normalize the image
    return img.reshape(-1, 48, 48, 1)  # Reshape for CNN input

def predict_emotion(image_path, model):
    img = preprocess_image(image_path)
    predicted = model.predict(img)
    predicted_label = np.argmax(predicted, axis=1)
    return label_encoder.inverse_transform(predicted_label)[0]

# Example usage: Predict the emotion of a new uploaded image
uploaded_image_path = '/content/Training_1206.jpg'  # Change this to the path of the uploaded image
predicted_emotion = predict_emotion(uploaded_image_path, model)
print(f'The predicted emotion for the uploaded image is: {predicted_emotion}')