# -*- coding: utf-8 -*-
"""EmotionDetectionKNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p3YL2C1PF9afaEklq32mG8GWancZLgYm
"""

import zipfile
with zipfile.ZipFile('/content/archive (1) (1).zip', 'r') as zip_ref:
    zip_ref.extractall('/content/')

# Import necessary libraries
import os
import numpy as np
import cv2
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from skimage.feature import hog
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import GridSearchCV

# Load and preprocess dataset
def load_images_for_knn(folder):
    images = []
    labels = []
    for label in os.listdir(folder):
        label_path = os.path.join(folder, label)
        for filename in os.listdir(label_path):
            img_path = os.path.join(label_path, filename)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale
            img = cv2.resize(img, (48, 48))  # Resize to 48x48
            if img is not None:
                # Extract HOG features
                hog_features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)
                images.append(hog_features)
                labels.append(label)
    return np.array(images), np.array(labels)

# Load train and test sets
train_dir = '/content/train'
val_dir = '/content/test'
X_train, y_train = load_images_for_knn(train_dir)
X_test, y_test = load_images_for_knn(val_dir)

# Convert string labels to numerical labels
label_encoder = LabelEncoder()

# Fit the label encoder to the training labels
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Normalize the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Apply PCA for dimensionality reduction
pca = PCA(n_components=150)  # Adjust n_components based on performance
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Define a parameter grid for KNN
param_grid = {
    'n_neighbors': [3, 5, 7, 9],  # Try different numbers of neighbors
    'weights': ['uniform', 'distance'],  # 'uniform' or 'distance'-based weighting
    'metric': ['euclidean', 'manhattan']  # Try different distance metrics
}

# Perform grid search to find the best parameters
grid = GridSearchCV(KNeighborsClassifier(), param_grid, refit=True, verbose=2)
grid.fit(X_train_pca, y_train_encoded)

# Use the best parameters found during GridSearchCV
best_knn = grid.best_estimator_

# Make predictions using the best model
y_pred_encoded = best_knn.predict(X_test_pca)

# Convert numeric predictions back to the original string labels
y_pred = label_encoder.inverse_transform(y_pred_encoded)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy after tuning: {accuracy * 100:.2f}%")

# Generate confusion matrix and classification report
cm = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("\nConfusion Matrix:\n", cm)
print("\nClassification Report:\n", report)

# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_train), yticklabels=np.unique(y_train))
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Summary and final steps:
print("Summary of KNN Model Optimization:")
print("""
1. Feature Extraction: Using HOG features for facial feature extraction.
2. PCA: Principal Component Analysis (PCA) for reducing the dimensionality of feature space.
3. Grid Search: Tuning 'n_neighbors', 'weights', and 'metric' to find the best KNN configuration.
4. Label Encoding: Convert string labels ('angry', 'happy') into numerical labels for KNN.
5. Normalize Data: Data is normalized before training KNN to improve performance.
""")

# Bar chart for actual vs predicted label distribution
actual_counts = np.array([np.sum(y_test == label) for label in label_encoder.classes_])
predicted_counts = np.array([np.sum(y_pred == label) for label in label_encoder.classes_])

# Bar chart for comparison
fig, ax = plt.subplots(figsize=(10, 6))
bar_width = 0.35
index = np.arange(len(label_encoder.classes_))

bar1 = ax.bar(index, actual_counts, bar_width, label='Actual')
bar2 = ax.bar(index + bar_width, predicted_counts, bar_width, label='Predicted')

ax.set_xlabel('Emotions')
ax.set_ylabel('Count')
ax.set_title('Actual vs Predicted Labels Distribution')
ax.set_xticks(index + bar_width / 2)
ax.set_xticklabels(label_encoder.classes_)
ax.legend()

plt.show()

# Import necessary libraries
import os
import numpy as np
import cv2
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from skimage.feature import hog
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import GridSearchCV
import joblib  # For saving and loading models

# Load and preprocess dataset
def load_images_for_knn(folder):
    images = []
    labels = []
    for label in os.listdir(folder):
        label_path = os.path.join(folder, label)
        for filename in os.listdir(label_path):
            img_path = os.path.join(label_path, filename)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale
            img = cv2.resize(img, (48, 48))  # Resize to 48x48
            if img is not None:
                # Extract HOG features
                hog_features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)
                images.append(hog_features)
                labels.append(label)
    return np.array(images), np.array(labels)

# Load train and test sets
train_dir = '/content/train'
val_dir = '/content/test'
X_train, y_train = load_images_for_knn(train_dir)
X_test, y_test = load_images_for_knn(val_dir)

# Convert string labels to numerical labels
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Normalize the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Apply PCA for dimensionality reduction
pca = PCA(n_components=150)  # Adjust n_components based on performance
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Define a parameter grid for KNN
param_grid = {
    'n_neighbors': [1, 2, 4, 5, 6, 8, 10, 15, 20],  # Try different numbers of neighbors
    'weights': ['uniform', 'distance'],  # 'uniform' or 'distance'-based weighting
    'metric': ['euclidean', 'manhattan']  # Try different distance metrics
}

# Perform grid search to find the best parameters
grid = GridSearchCV(KNeighborsClassifier(), param_grid, refit=True, verbose=2)
grid.fit(X_train_pca, y_train_encoded)

# Use the best parameters found during GridSearchCV
best_knn = grid.best_estimator_

# Save the scaler and PCA
joblib.dump(scaler, 'scaler.pkl')  # Save the scaler
joblib.dump(pca, 'pca.pkl')  # Save the PCA model

# Make predictions using the best model
y_pred_encoded = best_knn.predict(X_test_pca)

# Convert numeric predictions back to the original string labels
y_pred = label_encoder.inverse_transform(y_pred_encoded)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy after tuning: {accuracy * 100:.2f}%")

# Generate confusion matrix and classification report
cm = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("\nConfusion Matrix:\n", cm)
print("\nClassification Report:\n", report)

# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_train), yticklabels=np.unique(y_train))
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Testing with a new image
def preprocess_image(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale
    img = cv2.resize(img, (48, 48))  # Resize to 48x48
    hog_features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)
    return hog_features

def predict_emotion(image_path, knn_model):
    hog_features = preprocess_image(image_path)
    hog_features_scaled = scaler.transform([hog_features])  # Scale the features
    hog_features_pca = pca.transform(hog_features_scaled)  # Transform with PCA
    predicted_label_encoded = knn_model.predict(hog_features_pca)
    predicted_label = label_encoder.inverse_transform(predicted_label_encoded)
    return predicted_label[0]

# Example usage: Predict the emotion of a new uploaded image
uploaded_image_path = '/content/Training_1206.jpg'  # Change this to the path of the uploaded image
predicted_emotion = predict_emotion(uploaded_image_path, best_knn)
print(f'The predicted emotion for the uploaded image is: {predicted_emotion}')

import cv2
import numpy as np
from skimage.feature import hog
import joblib  # For loading the scaler and PCA

# Load the saved scaler and PCA
scaler = joblib.load('scaler.pkl')  # Load the scaler
pca = joblib.load('pca.pkl')         # Load the PCA model

# Function to preprocess a single image
def preprocess_image(image_path):
    # Load the image
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale
    img = cv2.resize(img, (48, 48))  # Resize to 48x48
    # Extract HOG features
    hog_features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)
    return hog_features

# Function to predict the emotion of the uploaded image
def predict_emotion(image_path, knn_model):
    # Preprocess the image
    hog_features = preprocess_image(image_path)

    # Normalize the features
    hog_features_scaled = scaler.transform([hog_features])  # Scale the features

    # Apply PCA transformation
    hog_features_pca = pca.transform(hog_features_scaled)  # Transform with PCA

    # Predict using the trained KNN model
    predicted_label_encoded = knn_model.predict(hog_features_pca)

    # Convert the predicted label back to the original emotion label
    predicted_label = label_encoder.inverse_transform(predicted_label_encoded)

    return predicted_label[0]

# Example usage: Predict the emotion of a new uploaded image
uploaded_image_path = '/content/PrivateTest_166793.jpg'  # Change this to the path of the uploaded image
predicted_emotion = predict_emotion(uploaded_image_path, best_knn)
print(f'The predicted emotion for the uploaded image is: {predicted_emotion}')

# Import necessary libraries
from sklearn.model_selection import KFold, cross_val_score

# Define K-Fold Cross-Validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation

# Initialize KNN
knn = KNeighborsClassifier(n_neighbors=5)  # You can experiment with different values of n_neighbors

# Perform cross-validation
cv_scores = cross_val_score(knn, X_train_pca, y_train_encoded, cv=kf)

# Output the results
print(f"Cross-Validation Scores: {cv_scores}")
print(f"Mean Cross-Validation Score: {np.mean(cv_scores):.2f} ± {np.std(cv_scores):.2f}")

import matplotlib.pyplot as plt
import numpy as np

# Example K-Fold Cross-Validation scores
cv_scores = np.array([0.45820272, 0.45733194, 0.45053988, 0.45837687, 0.44539279])  # Replace with your scores
mean_score = np.mean(cv_scores)
std_score = np.std(cv_scores)

# Create a plot for K-Fold Cross-Validation Scores
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(cv_scores) + 1), cv_scores, marker='o', linestyle='-', color='blue', label='Cross-Validation Score')
plt.axhline(mean_score, color='red', linestyle='--', label=f'Mean Score: {mean_score:.2f} ± {std_score:.2f}')

# Adding labels and title
plt.title('K-Fold Cross-Validation Scores for KNN')
plt.xlabel('Fold Number')
plt.ylabel('Accuracy Score')
plt.xticks(range(1, len(cv_scores) + 1))
plt.ylim(0, 1)  # Set y-axis limits from 0 to 1
plt.legend()
plt.grid()

# Show the plot
plt.show()